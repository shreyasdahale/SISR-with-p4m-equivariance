{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46a42a8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:54:13.216364Z",
     "iopub.status.busy": "2024-12-23T08:54:13.216062Z",
     "iopub.status.idle": "2024-12-23T08:54:18.259353Z",
     "shell.execute_reply": "2024-12-23T08:54:18.258482Z"
    },
    "papermill": {
     "duration": 5.050525,
     "end_time": "2024-12-23T08:54:18.261034",
     "exception": false,
     "start_time": "2024-12-23T08:54:13.210509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting e2cnn\r\n",
      "  Downloading e2cnn-0.2.3-py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from e2cnn) (2.4.1+cu121)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from e2cnn) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from e2cnn) (1.13.1)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from e2cnn) (1.13.3)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->e2cnn) (1.3.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->e2cnn) (3.16.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->e2cnn) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->e2cnn) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->e2cnn) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->e2cnn) (2024.6.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->e2cnn) (2.1.5)\r\n",
      "Downloading e2cnn-0.2.3-py3-none-any.whl (225 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/225.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: e2cnn\r\n",
      "Successfully installed e2cnn-0.2.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade e2cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "477f879a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-23T08:54:18.271852Z",
     "iopub.status.busy": "2024-12-23T08:54:18.271541Z",
     "iopub.status.idle": "2024-12-23T08:54:25.714621Z",
     "shell.execute_reply": "2024-12-23T08:54:25.713631Z"
    },
    "papermill": {
     "duration": 7.450296,
     "end_time": "2024-12-23T08:54:25.716401",
     "exception": false,
     "start_time": "2024-12-23T08:54:18.266105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tqdm\n",
    "import torch\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from datasets import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from e2cnn import gspaces\n",
    "from e2cnn.nn import GeometricTensor, FieldType, R2Conv, PointwiseAvgPoolAntialiased\n",
    "from e2cnn.gspaces import FlipRot2dOnR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "645c22a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:54:25.726490Z",
     "iopub.status.busy": "2024-12-23T08:54:25.726061Z",
     "iopub.status.idle": "2024-12-23T08:54:25.779385Z",
     "shell.execute_reply": "2024-12-23T08:54:25.778559Z"
    },
    "papermill": {
     "duration": 0.05969,
     "end_time": "2024-12-23T08:54:25.780664",
     "exception": false,
     "start_time": "2024-12-23T08:54:25.720974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9b1d1f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:54:25.790678Z",
     "iopub.status.busy": "2024-12-23T08:54:25.790374Z",
     "iopub.status.idle": "2024-12-23T08:55:00.142235Z",
     "shell.execute_reply": "2024-12-23T08:55:00.141481Z"
    },
    "papermill": {
     "duration": 34.358797,
     "end_time": "2024-12-23T08:55:00.144034",
     "exception": false,
     "start_time": "2024-12-23T08:54:25.785237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_dir = '/kaggle/input/task41/train/train'\n",
    "gt_dir = '/kaggle/input/task41/train/gt'\n",
    "\n",
    "image_files = sorted(os.listdir(image_dir))\n",
    "gt_files = sorted(os.listdir(gt_dir))\n",
    "\n",
    "imgs = []\n",
    "gt = []\n",
    "\n",
    "for i in range(len(os.listdir(image_dir))):\n",
    "    imgs.append(cv2.imread(os.path.join(image_dir, image_files[i])))\n",
    "    gt.append(cv2.imread(os.path.join(gt_dir, gt_files[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "346e853b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:55:00.158184Z",
     "iopub.status.busy": "2024-12-23T08:55:00.157912Z",
     "iopub.status.idle": "2024-12-23T08:55:07.657783Z",
     "shell.execute_reply": "2024-12-23T08:55:07.656902Z"
    },
    "papermill": {
     "duration": 7.507873,
     "end_time": "2024-12-23T08:55:07.659361",
     "exception": false,
     "start_time": "2024-12-23T08:55:00.151488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs_val_dir = '/kaggle/input/task41/val/val'\n",
    "gt_val_dir = '/kaggle/input/task41/val/gt'\n",
    "\n",
    "image_files_val = sorted(os.listdir(imgs_val_dir))\n",
    "gt_files_val = sorted(os.listdir(gt_val_dir))\n",
    "\n",
    "imgs_val = []\n",
    "gt_val = []\n",
    "\n",
    "for i in range(len(os.listdir(imgs_val_dir))):\n",
    "    imgs_val.append(cv2.imread(os.path.join(imgs_val_dir, image_files_val[i])))\n",
    "    gt_val.append(cv2.imread(os.path.join(gt_val_dir, gt_files_val[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cee7463",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:55:07.669334Z",
     "iopub.status.busy": "2024-12-23T08:55:07.669097Z",
     "iopub.status.idle": "2024-12-23T08:55:08.333344Z",
     "shell.execute_reply": "2024-12-23T08:55:08.332498Z"
    },
    "papermill": {
     "duration": 0.671028,
     "end_time": "2024-12-23T08:55:08.335057",
     "exception": false,
     "start_time": "2024-12-23T08:55:07.664029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs = np.array(imgs)\n",
    "gt= np.array(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdc1c466",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:55:08.344873Z",
     "iopub.status.busy": "2024-12-23T08:55:08.344577Z",
     "iopub.status.idle": "2024-12-23T08:55:08.664880Z",
     "shell.execute_reply": "2024-12-23T08:55:08.663800Z"
    },
    "papermill": {
     "duration": 0.327153,
     "end_time": "2024-12-23T08:55:08.666851",
     "exception": false,
     "start_time": "2024-12-23T08:55:08.339698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs_val = np.array(imgs_val)\n",
    "gt_val = np.array(gt_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dae3cb01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:55:08.677075Z",
     "iopub.status.busy": "2024-12-23T08:55:08.676785Z",
     "iopub.status.idle": "2024-12-23T08:55:08.682468Z",
     "shell.execute_reply": "2024-12-23T08:55:08.681714Z"
    },
    "papermill": {
     "duration": 0.012203,
     "end_time": "2024-12-23T08:55:08.683757",
     "exception": false,
     "start_time": "2024-12-23T08:55:08.671554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1105, 160, 256, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fcb2cbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:55:08.694397Z",
     "iopub.status.busy": "2024-12-23T08:55:08.694132Z",
     "iopub.status.idle": "2024-12-23T08:55:14.798365Z",
     "shell.execute_reply": "2024-12-23T08:55:14.797629Z"
    },
    "papermill": {
     "duration": 6.111192,
     "end_time": "2024-12-23T08:55:14.799992",
     "exception": false,
     "start_time": "2024-12-23T08:55:08.688800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = [(transforms.ToTensor()(imgs[i]), transforms.ToTensor()(gt[i])) for i in range(len(imgs))]\n",
    "data_val = [(transforms.ToTensor()(imgs_val[i]), transforms.ToTensor()(gt_val[i])) for i in range(len(imgs_val))]\n",
    "\n",
    "train = DataLoader(data, batch_size=8, shuffle=True)\n",
    "val = DataLoader(data_val, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfc0e1da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:55:14.812501Z",
     "iopub.status.busy": "2024-12-23T08:55:14.812251Z",
     "iopub.status.idle": "2024-12-23T08:55:14.826872Z",
     "shell.execute_reply": "2024-12-23T08:55:14.826266Z"
    },
    "papermill": {
     "duration": 0.022256,
     "end_time": "2024-12-23T08:55:14.828150",
     "exception": false,
     "start_time": "2024-12-23T08:55:14.805894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.fc1 = nn.Conv2d(in_channels, in_channels // reduction, kernel_size=1, bias=True)\n",
    "        self.fc2 = nn.Conv2d(in_channels // reduction, in_channels, kernel_size=1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_pool = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        max_pool = F.adaptive_max_pool2d(x, (1, 1))\n",
    "        out = self.fc1(avg_pool) + self.fc1(max_pool)\n",
    "        out = F.relu(out, inplace=True)\n",
    "        out = self.fc2(out)\n",
    "        return x * torch.sigmoid(out)\n",
    "\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=(kernel_size // 2), bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        out = torch.cat([avg_out, max_out], dim=1)\n",
    "        out = self.conv(out)\n",
    "        return x * torch.sigmoid(out)\n",
    "\n",
    "\n",
    "class GInceptionModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, gspace, dilation=2):\n",
    "        super(GInceptionModule, self).__init__()\n",
    "        self.gspace = gspace\n",
    "        group_size = len(self.gspace.fibergroup.elements)\n",
    "\n",
    "        self.field_in = FieldType(self.gspace, [self.gspace.regular_repr] * (in_channels // group_size))\n",
    "        self.field_out = FieldType(self.gspace, [self.gspace.regular_repr] * (out_channels // group_size))\n",
    "\n",
    "        self.conv1x1 = R2Conv(self.field_in, self.field_out, kernel_size=1)\n",
    "        self.conv3x3 = R2Conv(self.field_in, self.field_out, kernel_size=3, padding=1)\n",
    "        self.conv_dilated = R2Conv(self.field_in, self.field_out, kernel_size=3, padding=dilation, dilation=dilation)\n",
    "        self.pool = PointwiseAvgPoolAntialiased(self.field_in, sigma=0.66, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not isinstance(x, GeometricTensor):\n",
    "            geo_x = GeometricTensor(x, self.field_in)\n",
    "        else:\n",
    "            geo_x = x\n",
    "\n",
    "        out1 = self.conv1x1(geo_x).tensor\n",
    "        out2 = self.conv3x3(geo_x).tensor\n",
    "        out3 = self.conv_dilated(geo_x).tensor\n",
    "        out4 = self.pool(geo_x).tensor\n",
    "\n",
    "        out = torch.cat([out1, out2, out3, out4], dim=1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, gspace):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.ginception = GInceptionModule(in_channels, in_channels, gspace)\n",
    "        concatenated_channels = in_channels * 4\n",
    "        self.project = nn.Conv2d(concatenated_channels, in_channels, kernel_size=3, padding=1, bias=True)\n",
    "        self.ca = ChannelAttention(in_channels)\n",
    "        self.sa = SpatialAttention()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.ginception(x)\n",
    "        out = self.project(out)\n",
    "        out = self.ca(out)\n",
    "        out = self.sa(out)\n",
    "        return out + residual\n",
    "\n",
    "\n",
    "class UpscaleBlock(nn.Module):\n",
    "    def __init__(self, in_channels, scale_factor):\n",
    "        super(UpscaleBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, in_channels * (scale_factor ** 2), kernel_size=3, padding=1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(scale_factor)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.pixel_shuffle(out)\n",
    "        return F.relu(out, inplace=True)\n",
    "\n",
    "\n",
    "class SISRModel(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_features=64, num_res_blocks=8, scale_factor=4):\n",
    "        super(SISRModel, self).__init__()\n",
    "        self.gspace = FlipRot2dOnR2(N=4)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, num_features, kernel_size=3, padding=1)\n",
    "        self.res_blocks = nn.Sequential(\n",
    "            *[ResidualBlock(num_features, self.gspace) for _ in range(num_res_blocks)]\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(num_features, num_features, kernel_size=3, padding=1)\n",
    "        self.upscale = UpscaleBlock(num_features, scale_factor)\n",
    "        self.conv3 = nn.Conv2d(num_features, in_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        initial_features = F.relu(self.conv1(x), inplace=True)\n",
    "        features = self.res_blocks(initial_features)\n",
    "        features = self.conv2(features) + initial_features\n",
    "        upscaled = self.upscale(features)\n",
    "        output = self.conv3(upscaled)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa0acc5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:55:14.837635Z",
     "iopub.status.busy": "2024-12-23T08:55:14.837369Z",
     "iopub.status.idle": "2024-12-23T08:55:15.757887Z",
     "shell.execute_reply": "2024-12-23T08:55:15.756993Z"
    },
    "papermill": {
     "duration": 0.926718,
     "end_time": "2024-12-23T08:55:15.759257",
     "exception": false,
     "start_time": "2024-12-23T08:55:14.832539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/e2cnn/nn/modules/r2_conv/basisexpansion_singleblock.py:80: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
      "  full_mask[mask] = norms.to(torch.uint8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SISRModel(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (res_blocks): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (ginception): GInceptionModule(\n",
       "        (conv1x1): R2Conv([Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], [Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1)\n",
       "        (conv3x3): R2Conv([Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], [Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=1)\n",
       "        (conv_dilated): R2Conv([Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], [Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=2, dilation=2)\n",
       "        (pool): PointwiseAvgPoolAntialiased()\n",
       "      )\n",
       "      (project): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (ca): ChannelAttention(\n",
       "        (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (sa): SpatialAttention(\n",
       "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (ginception): GInceptionModule(\n",
       "        (conv1x1): R2Conv([Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], [Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1)\n",
       "        (conv3x3): R2Conv([Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], [Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=1)\n",
       "        (conv_dilated): R2Conv([Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], [Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=2, dilation=2)\n",
       "        (pool): PointwiseAvgPoolAntialiased()\n",
       "      )\n",
       "      (project): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (ca): ChannelAttention(\n",
       "        (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (sa): SpatialAttention(\n",
       "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (ginception): GInceptionModule(\n",
       "        (conv1x1): R2Conv([Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], [Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1)\n",
       "        (conv3x3): R2Conv([Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], [Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=1)\n",
       "        (conv_dilated): R2Conv([Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], [Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=2, dilation=2)\n",
       "        (pool): PointwiseAvgPoolAntialiased()\n",
       "      )\n",
       "      (project): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (ca): ChannelAttention(\n",
       "        (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (sa): SpatialAttention(\n",
       "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (ginception): GInceptionModule(\n",
       "        (conv1x1): R2Conv([Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], [Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1)\n",
       "        (conv3x3): R2Conv([Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], [Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=1)\n",
       "        (conv_dilated): R2Conv([Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], [Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=2, dilation=2)\n",
       "        (pool): PointwiseAvgPoolAntialiased()\n",
       "      )\n",
       "      (project): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (ca): ChannelAttention(\n",
       "        (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (sa): SpatialAttention(\n",
       "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (ginception): GInceptionModule(\n",
       "        (conv1x1): R2Conv([Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], [Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1)\n",
       "        (conv3x3): R2Conv([Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], [Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=1)\n",
       "        (conv_dilated): R2Conv([Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], [Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=2, dilation=2)\n",
       "        (pool): PointwiseAvgPoolAntialiased()\n",
       "      )\n",
       "      (project): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (ca): ChannelAttention(\n",
       "        (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (sa): SpatialAttention(\n",
       "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (5): ResidualBlock(\n",
       "      (ginception): GInceptionModule(\n",
       "        (conv1x1): R2Conv([Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], [Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1)\n",
       "        (conv3x3): R2Conv([Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], [Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=1)\n",
       "        (conv_dilated): R2Conv([Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], [Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=2, dilation=2)\n",
       "        (pool): PointwiseAvgPoolAntialiased()\n",
       "      )\n",
       "      (project): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (ca): ChannelAttention(\n",
       "        (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (sa): SpatialAttention(\n",
       "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (6): ResidualBlock(\n",
       "      (ginception): GInceptionModule(\n",
       "        (conv1x1): R2Conv([Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], [Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1)\n",
       "        (conv3x3): R2Conv([Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], [Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=1)\n",
       "        (conv_dilated): R2Conv([Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], [Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=2, dilation=2)\n",
       "        (pool): PointwiseAvgPoolAntialiased()\n",
       "      )\n",
       "      (project): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (ca): ChannelAttention(\n",
       "        (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (sa): SpatialAttention(\n",
       "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (7): ResidualBlock(\n",
       "      (ginception): GInceptionModule(\n",
       "        (conv1x1): R2Conv([Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], [Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=1, stride=1)\n",
       "        (conv3x3): R2Conv([Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], [Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=1)\n",
       "        (conv_dilated): R2Conv([Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], [Flip_4-Rotations(f=1.57080): {regular, regular, regular, regular, regular, regular, regular, regular}], kernel_size=3, stride=1, padding=2, dilation=2)\n",
       "        (pool): PointwiseAvgPoolAntialiased()\n",
       "      )\n",
       "      (project): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (ca): ChannelAttention(\n",
       "        (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (sa): SpatialAttention(\n",
       "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (upscale): UpscaleBlock(\n",
       "    (conv): Conv2d(64, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (pixel_shuffle): PixelShuffle(upscale_factor=4)\n",
       "  )\n",
       "  (conv3): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SISRModel()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e70b2e46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:55:15.770128Z",
     "iopub.status.busy": "2024-12-23T08:55:15.769885Z",
     "iopub.status.idle": "2024-12-23T08:55:15.996852Z",
     "shell.execute_reply": "2024-12-23T08:55:15.995718Z"
    },
    "papermill": {
     "duration": 0.234258,
     "end_time": "2024-12-23T08:55:15.998441",
     "exception": false,
     "start_time": "2024-12-23T08:55:15.764183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 1878515\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cd541bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:55:16.009867Z",
     "iopub.status.busy": "2024-12-23T08:55:16.009561Z",
     "iopub.status.idle": "2024-12-23T08:55:16.073794Z",
     "shell.execute_reply": "2024-12-23T08:55:16.072886Z"
    },
    "papermill": {
     "duration": 0.071101,
     "end_time": "2024-12-23T08:55:16.075386",
     "exception": false,
     "start_time": "2024-12-23T08:55:16.004285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=4e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4684cb38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T08:55:16.085960Z",
     "iopub.status.busy": "2024-12-23T08:55:16.085727Z",
     "iopub.status.idle": "2024-12-23T09:50:08.168462Z",
     "shell.execute_reply": "2024-12-23T09:50:08.167515Z"
    },
    "papermill": {
     "duration": 3292.094344,
     "end_time": "2024-12-23T09:50:08.174807",
     "exception": false,
     "start_time": "2024-12-23T08:55:16.080463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.0016734298118038385, Validation Loss: 0.0002877890595422585\n",
      "Validation loss improved from inf to 0.0002877890595422585. Saving best weights.\n",
      "Epoch 2/100, Train Loss: 0.00042629054841324154, Validation Loss: 0.00024252450895068277\n",
      "Validation loss improved from 0.0002877890595422585 to 0.00024252450895068277. Saving best weights.\n",
      "Epoch 3/100, Train Loss: 0.0003710974938748739, Validation Loss: 0.00021913347523850598\n",
      "Validation loss improved from 0.00024252450895068277 to 0.00021913347523850598. Saving best weights.\n",
      "Epoch 4/100, Train Loss: 0.00034277920385909755, Validation Loss: 0.0002030534818533933\n",
      "Validation loss improved from 0.00021913347523850598 to 0.0002030534818533933. Saving best weights.\n",
      "Epoch 5/100, Train Loss: 0.0003216882089107706, Validation Loss: 0.00020136050432538198\n",
      "Validation loss improved from 0.0002030534818533933 to 0.00020136050432538198. Saving best weights.\n",
      "Epoch 6/100, Train Loss: 0.0003090965698293926, Validation Loss: 0.00018599667231710418\n",
      "Validation loss improved from 0.00020136050432538198 to 0.00018599667231710418. Saving best weights.\n",
      "Epoch 7/100, Train Loss: 0.00030125990901946377, Validation Loss: 0.00018439548799886244\n",
      "Validation loss improved from 0.00018599667231710418 to 0.00018439548799886244. Saving best weights.\n",
      "Epoch 8/100, Train Loss: 0.00029443939473553686, Validation Loss: 0.0001799669756911132\n",
      "Validation loss improved from 0.00018439548799886244 to 0.0001799669756911132. Saving best weights.\n",
      "Epoch 9/100, Train Loss: 0.00028918165417903994, Validation Loss: 0.0001749093323961637\n",
      "Validation loss improved from 0.0001799669756911132 to 0.0001749093323961637. Saving best weights.\n",
      "Epoch 10/100, Train Loss: 0.0002839954374374808, Validation Loss: 0.00017185865732217417\n",
      "Validation loss improved from 0.0001749093323961637 to 0.00017185865732217417. Saving best weights.\n",
      "Epoch 11/100, Train Loss: 0.00027980495381617934, Validation Loss: 0.0001766924442156086\n",
      "No improvement for 1 epochs.\n",
      "Epoch 12/100, Train Loss: 0.0002796415892000839, Validation Loss: 0.00017661222547975564\n",
      "No improvement for 2 epochs.\n",
      "Epoch 13/100, Train Loss: 0.00027707275771619687, Validation Loss: 0.00016399120230839323\n",
      "Validation loss improved from 0.00017185865732217417 to 0.00016399120230839323. Saving best weights.\n",
      "Epoch 14/100, Train Loss: 0.00027355108137507153, Validation Loss: 0.00016491454017110544\n",
      "No improvement for 1 epochs.\n",
      "Epoch 15/100, Train Loss: 0.00027225796615272735, Validation Loss: 0.00016303704794167902\n",
      "Validation loss improved from 0.00016399120230839323 to 0.00016303704794167902. Saving best weights.\n",
      "Epoch 16/100, Train Loss: 0.0002713229055156288, Validation Loss: 0.00016471785881970105\n",
      "No improvement for 1 epochs.\n",
      "Epoch 17/100, Train Loss: 0.00027045620778716245, Validation Loss: 0.0001675386431712984\n",
      "No improvement for 2 epochs.\n",
      "Epoch 18/100, Train Loss: 0.00026895693851309904, Validation Loss: 0.0001654253180969312\n",
      "No improvement for 3 epochs.\n",
      "Epoch 19/100, Train Loss: 0.00026930601331036835, Validation Loss: 0.00016474792921225846\n",
      "No improvement for 4 epochs.\n",
      "Epoch 20/100, Train Loss: 0.0002677408315026932, Validation Loss: 0.00015939675347962932\n",
      "Validation loss improved from 0.00016303704794167902 to 0.00015939675347962932. Saving best weights.\n",
      "Epoch 21/100, Train Loss: 0.0002636299356558568, Validation Loss: 0.00016159234259411373\n",
      "No improvement for 1 epochs.\n",
      "Epoch 22/100, Train Loss: 0.0002634015618764842, Validation Loss: 0.00016161932798064272\n",
      "No improvement for 2 epochs.\n",
      "Epoch 23/100, Train Loss: 0.00026266447931323734, Validation Loss: 0.00015971635475037132\n",
      "No improvement for 3 epochs.\n",
      "Epoch 24/100, Train Loss: 0.0002636126916363112, Validation Loss: 0.00016470503244668926\n",
      "No improvement for 4 epochs.\n",
      "Epoch 25/100, Train Loss: 0.0002616039711166267, Validation Loss: 0.00015983650182398146\n",
      "No improvement for 5 epochs.\n",
      "Early stopping due to no improvement in validation loss.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import torch.optim as optim\n",
    "\n",
    "num_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "best_model_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for imgs, depths in train:\n",
    "        imgs = imgs.to(device)\n",
    "        depths = depths.to(device)\n",
    "        outputs = model(imgs)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, depths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, depths in val:\n",
    "            imgs = imgs.to(device)\n",
    "            depths = depths.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, depths)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(val)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss}, Validation Loss: {val_loss}\")\n",
    "\n",
    "    # Check for improvement\n",
    "    if val_loss < best_val_loss:\n",
    "        print(f\"Validation loss improved from {best_val_loss} to {val_loss}. Saving best weights.\")\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement for {patience_counter} epochs.\")\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping due to no improvement in validation loss.\")\n",
    "        break\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "model.load_state_dict(best_model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f406035",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:50:08.188000Z",
     "iopub.status.busy": "2024-12-23T09:50:08.187762Z",
     "iopub.status.idle": "2024-12-23T09:50:08.777407Z",
     "shell.execute_reply": "2024-12-23T09:50:08.776698Z"
    },
    "papermill": {
     "duration": 0.598305,
     "end_time": "2024-12-23T09:50:08.779069",
     "exception": false,
     "start_time": "2024-12-23T09:50:08.180764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "torch.save(model, \"model.pth\", pickle_module=dill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41ca8a47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:50:08.792781Z",
     "iopub.status.busy": "2024-12-23T09:50:08.792503Z",
     "iopub.status.idle": "2024-12-23T09:50:09.402128Z",
     "shell.execute_reply": "2024-12-23T09:50:09.401401Z"
    },
    "papermill": {
     "duration": 0.61826,
     "end_time": "2024-12-23T09:50:09.403692",
     "exception": false,
     "start_time": "2024-12-23T09:50:08.785432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_dir_test = '/kaggle/input/task41/test'\n",
    "image_files_test = sorted(os.listdir(image_dir_test))\n",
    "\n",
    "imgs_test = []\n",
    "\n",
    "for i in range(len(os.listdir(image_dir_test))):\n",
    "    imgs_test.append(cv2.imread(os.path.join(image_dir_test, image_files_test[i])))\n",
    "\n",
    "imgs_test = np.array(imgs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e778566",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:50:09.416934Z",
     "iopub.status.busy": "2024-12-23T09:50:09.416692Z",
     "iopub.status.idle": "2024-12-23T09:50:09.421147Z",
     "shell.execute_reply": "2024-12-23T09:50:09.420504Z"
    },
    "papermill": {
     "duration": 0.012276,
     "end_time": "2024-12-23T09:50:09.422336",
     "exception": false,
     "start_time": "2024-12-23T09:50:09.410060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 160, 256, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "401e40a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:50:09.434640Z",
     "iopub.status.busy": "2024-12-23T09:50:09.434400Z",
     "iopub.status.idle": "2024-12-23T09:50:09.446857Z",
     "shell.execute_reply": "2024-12-23T09:50:09.446031Z"
    },
    "papermill": {
     "duration": 0.019999,
     "end_time": "2024-12-23T09:50:09.448096",
     "exception": false,
     "start_time": "2024-12-23T09:50:09.428097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = [transforms.ToTensor()(imgs_test[i]) for i in range(len(imgs_test))]\n",
    "test = DataLoader(data, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce929e67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:50:09.463160Z",
     "iopub.status.busy": "2024-12-23T09:50:09.462882Z",
     "iopub.status.idle": "2024-12-23T09:50:12.147618Z",
     "shell.execute_reply": "2024-12-23T09:50:12.146640Z"
    },
    "papermill": {
     "duration": 2.693701,
     "end_time": "2024-12-23T09:50:12.149235",
     "exception": false,
     "start_time": "2024-12-23T09:50:09.455534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for imgs in test:\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model(imgs)\n",
    "        preds.extend(outputs.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fca8e5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:50:12.162215Z",
     "iopub.status.busy": "2024-12-23T09:50:12.161947Z",
     "iopub.status.idle": "2024-12-23T09:50:12.557486Z",
     "shell.execute_reply": "2024-12-23T09:50:12.556518Z"
    },
    "papermill": {
     "duration": 0.403821,
     "end_time": "2024-12-23T09:50:12.559259",
     "exception": false,
     "start_time": "2024-12-23T09:50:12.155438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = np.array(preds)\n",
    "preds.shape\n",
    "preds = (preds * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "206b5058",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:50:12.572462Z",
     "iopub.status.busy": "2024-12-23T09:50:12.572188Z",
     "iopub.status.idle": "2024-12-23T09:50:14.802506Z",
     "shell.execute_reply": "2024-12-23T09:50:14.801557Z"
    },
    "papermill": {
     "duration": 2.238583,
     "end_time": "2024-12-23T09:50:14.804246",
     "exception": false,
     "start_time": "2024-12-23T09:50:12.565663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = \"output_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for idx, img in enumerate(preds):\n",
    "    img = img.transpose(1, 2, 0)\n",
    "    filename = os.path.join(output_dir, f\"gt_{idx:05d}.png\")\n",
    "    cv2.imwrite(filename, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49d71f49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T09:50:14.817946Z",
     "iopub.status.busy": "2024-12-23T09:50:14.817633Z",
     "iopub.status.idle": "2024-12-23T09:50:16.415971Z",
     "shell.execute_reply": "2024-12-23T09:50:16.415032Z"
    },
    "papermill": {
     "duration": 1.606738,
     "end_time": "2024-12-23T09:50:16.417485",
     "exception": false,
     "start_time": "2024-12-23T09:50:14.810747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "folder_to_zip = \"output_images\"\n",
    "zip_filename = \"zipped_folder.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for root, _, files in os.walk(folder_to_zip):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            arcname = os.path.relpath(file_path, folder_to_zip)\n",
    "            zipf.write(file_path, arcname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a5d20e",
   "metadata": {
    "papermill": {
     "duration": 0.005683,
     "end_time": "2024-12-23T09:50:16.429465",
     "exception": false,
     "start_time": "2024-12-23T09:50:16.423782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6341177,
     "sourceId": 10251813,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3368.18543,
   "end_time": "2024-12-23T09:50:19.213773",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-23T08:54:11.028343",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
