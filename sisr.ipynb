{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f61db0fe",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-23T18:40:15.607839Z",
     "iopub.status.busy": "2024-12-23T18:40:15.607556Z",
     "iopub.status.idle": "2024-12-23T18:40:22.014190Z",
     "shell.execute_reply": "2024-12-23T18:40:22.013476Z"
    },
    "papermill": {
     "duration": 6.41391,
     "end_time": "2024-12-23T18:40:22.015777",
     "exception": false,
     "start_time": "2024-12-23T18:40:15.601867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tqdm\n",
    "import torch\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from datasets import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eecf2e25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T18:40:22.024952Z",
     "iopub.status.busy": "2024-12-23T18:40:22.024559Z",
     "iopub.status.idle": "2024-12-23T18:40:22.088117Z",
     "shell.execute_reply": "2024-12-23T18:40:22.087440Z"
    },
    "papermill": {
     "duration": 0.069424,
     "end_time": "2024-12-23T18:40:22.089452",
     "exception": false,
     "start_time": "2024-12-23T18:40:22.020028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c10f9e0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T18:40:22.098087Z",
     "iopub.status.busy": "2024-12-23T18:40:22.097843Z",
     "iopub.status.idle": "2024-12-23T18:40:57.344864Z",
     "shell.execute_reply": "2024-12-23T18:40:57.343872Z"
    },
    "papermill": {
     "duration": 35.253092,
     "end_time": "2024-12-23T18:40:57.346620",
     "exception": false,
     "start_time": "2024-12-23T18:40:22.093528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_dir = '/kaggle/input/task-4-1/train/train'\n",
    "gt_dir = '/kaggle/input/task-4-1/train/gt'\n",
    "\n",
    "image_files = sorted(os.listdir(image_dir))\n",
    "gt_files = sorted(os.listdir(gt_dir))\n",
    "\n",
    "imgs = []\n",
    "gt = []\n",
    "\n",
    "for i in range(len(os.listdir(image_dir))):\n",
    "    imgs.append(cv2.imread(os.path.join(image_dir, image_files[i])))\n",
    "    gt.append(cv2.imread(os.path.join(gt_dir, gt_files[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9161500e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T18:40:57.355440Z",
     "iopub.status.busy": "2024-12-23T18:40:57.355154Z",
     "iopub.status.idle": "2024-12-23T18:41:04.703787Z",
     "shell.execute_reply": "2024-12-23T18:41:04.702798Z"
    },
    "papermill": {
     "duration": 7.354632,
     "end_time": "2024-12-23T18:41:04.705506",
     "exception": false,
     "start_time": "2024-12-23T18:40:57.350874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs_val_dir = '/kaggle/input/task-4-1/val/val'\n",
    "gt_val_dir = '/kaggle/input/task-4-1/val/gt'\n",
    "\n",
    "image_files_val = sorted(os.listdir(imgs_val_dir))\n",
    "gt_files_val = sorted(os.listdir(gt_val_dir))\n",
    "\n",
    "imgs_val = []\n",
    "gt_val = []\n",
    "\n",
    "for i in range(len(os.listdir(imgs_val_dir))):\n",
    "    imgs_val.append(cv2.imread(os.path.join(imgs_val_dir, image_files_val[i])))\n",
    "    gt_val.append(cv2.imread(os.path.join(gt_val_dir, gt_files_val[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce6d8f3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T18:41:04.714147Z",
     "iopub.status.busy": "2024-12-23T18:41:04.713892Z",
     "iopub.status.idle": "2024-12-23T18:41:05.405031Z",
     "shell.execute_reply": "2024-12-23T18:41:05.404130Z"
    },
    "papermill": {
     "duration": 0.697238,
     "end_time": "2024-12-23T18:41:05.406789",
     "exception": false,
     "start_time": "2024-12-23T18:41:04.709551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs = np.array(imgs)\n",
    "gt= np.array(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "029786a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T18:41:05.415387Z",
     "iopub.status.busy": "2024-12-23T18:41:05.415117Z",
     "iopub.status.idle": "2024-12-23T18:41:05.739182Z",
     "shell.execute_reply": "2024-12-23T18:41:05.738314Z"
    },
    "papermill": {
     "duration": 0.330055,
     "end_time": "2024-12-23T18:41:05.740876",
     "exception": false,
     "start_time": "2024-12-23T18:41:05.410821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs_val = np.array(imgs_val)\n",
    "gt_val = np.array(gt_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc1675ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T18:41:05.749782Z",
     "iopub.status.busy": "2024-12-23T18:41:05.749546Z",
     "iopub.status.idle": "2024-12-23T18:41:05.755441Z",
     "shell.execute_reply": "2024-12-23T18:41:05.754585Z"
    },
    "papermill": {
     "duration": 0.011617,
     "end_time": "2024-12-23T18:41:05.756777",
     "exception": false,
     "start_time": "2024-12-23T18:41:05.745160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1105, 160, 256, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b80e360b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T18:41:05.765425Z",
     "iopub.status.busy": "2024-12-23T18:41:05.765166Z",
     "iopub.status.idle": "2024-12-23T18:41:15.626602Z",
     "shell.execute_reply": "2024-12-23T18:41:15.625549Z"
    },
    "papermill": {
     "duration": 9.867872,
     "end_time": "2024-12-23T18:41:15.628577",
     "exception": false,
     "start_time": "2024-12-23T18:41:05.760705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = [(transforms.ToTensor()(imgs[i]), transforms.ToTensor()(gt[i])) for i in range(len(imgs))]\n",
    "data_val = [(transforms.ToTensor()(imgs_val[i]), transforms.ToTensor()(gt_val[i])) for i in range(len(imgs_val))]\n",
    "\n",
    "train = DataLoader(data, batch_size=8, shuffle=True)\n",
    "val = DataLoader(data_val, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "266aa2e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T18:41:15.639685Z",
     "iopub.status.busy": "2024-12-23T18:41:15.639376Z",
     "iopub.status.idle": "2024-12-23T18:41:15.654676Z",
     "shell.execute_reply": "2024-12-23T18:41:15.653942Z"
    },
    "papermill": {
     "duration": 0.022088,
     "end_time": "2024-12-23T18:41:15.655977",
     "exception": false,
     "start_time": "2024-12-23T18:41:15.633889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.fc1 = nn.Conv2d(in_channels, in_channels // reduction, kernel_size=1, bias=True)\n",
    "        self.fc2 = nn.Conv2d(in_channels // reduction, in_channels, kernel_size=1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_pool = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        max_pool = F.adaptive_max_pool2d(x, (1, 1))\n",
    "        out = self.fc1(avg_pool) + self.fc1(max_pool)\n",
    "        out = F.relu(out, inplace=True)\n",
    "        out = self.fc2(out)\n",
    "        return x * torch.sigmoid(out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=(kernel_size // 2), bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        out = torch.cat([avg_out, max_out], dim=1)\n",
    "        out = self.conv(out)\n",
    "        return x * torch.sigmoid(out)\n",
    "\n",
    "class InceptionModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dilation=2):\n",
    "        super(InceptionModule, self).__init__()\n",
    "        self.conv1x1 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        self.conv3x3 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv_dilated = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=dilation, dilation=dilation)\n",
    "        self.pool = nn.AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.conv1x1(x)\n",
    "        out2 = self.conv3x3(x)\n",
    "        out3 = self.conv_dilated(x)\n",
    "        out4 = self.pool(x)\n",
    "        out = torch.cat([out1, out2, out3, out4], dim=1)\n",
    "        return out\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.inception = InceptionModule(in_channels, in_channels)\n",
    "        concatenated_channels = in_channels * 4\n",
    "        self.project = nn.Conv2d(concatenated_channels, in_channels, kernel_size=3, padding=1, bias=True)\n",
    "        self.ca = ChannelAttention(in_channels)\n",
    "        self.sa = SpatialAttention()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.inception(x)\n",
    "        out = self.project(out)\n",
    "        out = self.ca(out)\n",
    "        out = self.sa(out)\n",
    "        return out + residual\n",
    "\n",
    "class UpscaleBlock(nn.Module):\n",
    "    def __init__(self, in_channels, scale_factor):\n",
    "        super(UpscaleBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, in_channels * (scale_factor ** 2), kernel_size=3, padding=1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(scale_factor)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.pixel_shuffle(out)\n",
    "        return F.relu(out, inplace=True)\n",
    "\n",
    "class SISRModel(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_features=64, num_res_blocks=8, scale_factor=4):\n",
    "        super(SISRModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, num_features, kernel_size=3, padding=1)\n",
    "        self.res_blocks = nn.Sequential(\n",
    "            *[ResidualBlock(num_features) for _ in range(num_res_blocks)]\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(num_features, num_features, kernel_size=3, padding=1)\n",
    "        self.upscale = UpscaleBlock(num_features, scale_factor)\n",
    "        self.conv3 = nn.Conv2d(num_features, in_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        initial_features = F.relu(self.conv1(x), inplace=True)\n",
    "        features = self.res_blocks(initial_features)\n",
    "        features = self.conv2(features) + initial_features\n",
    "        upscaled = self.upscale(features)\n",
    "        output = self.conv3(upscaled)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d10b0e13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T18:41:15.666399Z",
     "iopub.status.busy": "2024-12-23T18:41:15.666087Z",
     "iopub.status.idle": "2024-12-23T18:41:15.877102Z",
     "shell.execute_reply": "2024-12-23T18:41:15.876126Z"
    },
    "papermill": {
     "duration": 0.217601,
     "end_time": "2024-12-23T18:41:15.878432",
     "exception": false,
     "start_time": "2024-12-23T18:41:15.660831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SISRModel(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (res_blocks): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (inception): InceptionModule(\n",
       "        (conv1x1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3x3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_dilated): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "      )\n",
       "      (project): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (ca): ChannelAttention(\n",
       "        (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (sa): SpatialAttention(\n",
       "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (inception): InceptionModule(\n",
       "        (conv1x1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3x3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_dilated): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "      )\n",
       "      (project): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (ca): ChannelAttention(\n",
       "        (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (sa): SpatialAttention(\n",
       "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): ResidualBlock(\n",
       "      (inception): InceptionModule(\n",
       "        (conv1x1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3x3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_dilated): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "      )\n",
       "      (project): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (ca): ChannelAttention(\n",
       "        (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (sa): SpatialAttention(\n",
       "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3): ResidualBlock(\n",
       "      (inception): InceptionModule(\n",
       "        (conv1x1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3x3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_dilated): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "      )\n",
       "      (project): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (ca): ChannelAttention(\n",
       "        (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (sa): SpatialAttention(\n",
       "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (4): ResidualBlock(\n",
       "      (inception): InceptionModule(\n",
       "        (conv1x1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3x3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_dilated): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "      )\n",
       "      (project): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (ca): ChannelAttention(\n",
       "        (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (sa): SpatialAttention(\n",
       "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (5): ResidualBlock(\n",
       "      (inception): InceptionModule(\n",
       "        (conv1x1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3x3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_dilated): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "      )\n",
       "      (project): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (ca): ChannelAttention(\n",
       "        (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (sa): SpatialAttention(\n",
       "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (6): ResidualBlock(\n",
       "      (inception): InceptionModule(\n",
       "        (conv1x1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3x3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_dilated): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "      )\n",
       "      (project): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (ca): ChannelAttention(\n",
       "        (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (sa): SpatialAttention(\n",
       "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (7): ResidualBlock(\n",
       "      (inception): InceptionModule(\n",
       "        (conv1x1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3x3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_dilated): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "      )\n",
       "      (project): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (ca): ChannelAttention(\n",
       "        (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (sa): SpatialAttention(\n",
       "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (upscale): UpscaleBlock(\n",
       "    (conv): Conv2d(64, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (pixel_shuffle): PixelShuffle(upscale_factor=4)\n",
       "  )\n",
       "  (conv3): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SISRModel(in_channels=3, num_features=64, num_res_blocks=8, scale_factor=4)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05c8198a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T18:41:15.887782Z",
     "iopub.status.busy": "2024-12-23T18:41:15.887542Z",
     "iopub.status.idle": "2024-12-23T18:41:15.892106Z",
     "shell.execute_reply": "2024-12-23T18:41:15.891340Z"
    },
    "papermill": {
     "duration": 0.010637,
     "end_time": "2024-12-23T18:41:15.893306",
     "exception": false,
     "start_time": "2024-12-23T18:41:15.882669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 2441011\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fa4953d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T18:41:15.902212Z",
     "iopub.status.busy": "2024-12-23T18:41:15.901963Z",
     "iopub.status.idle": "2024-12-23T18:41:15.906403Z",
     "shell.execute_reply": "2024-12-23T18:41:15.905561Z"
    },
    "papermill": {
     "duration": 0.010257,
     "end_time": "2024-12-23T18:41:15.907603",
     "exception": false,
     "start_time": "2024-12-23T18:41:15.897346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00075)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e1b2e49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T18:41:15.916242Z",
     "iopub.status.busy": "2024-12-23T18:41:15.916010Z",
     "iopub.status.idle": "2024-12-23T19:44:55.969251Z",
     "shell.execute_reply": "2024-12-23T19:44:55.968298Z"
    },
    "papermill": {
     "duration": 3820.064185,
     "end_time": "2024-12-23T19:44:55.975818",
     "exception": false,
     "start_time": "2024-12-23T18:41:15.911633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 0.002050137425782896, Validation Loss: 0.00027552406108545476\n",
      "Validation loss improved from inf to 0.00027552406108545476. Saving best weights.\n",
      "Epoch 2/50, Train Loss: 0.0004093280099139703, Validation Loss: 0.00023047564726726\n",
      "Validation loss improved from 0.00027552406108545476 to 0.00023047564726726. Saving best weights.\n",
      "Epoch 3/50, Train Loss: 0.0003482635576226045, Validation Loss: 0.0002085324984418277\n",
      "Validation loss improved from 0.00023047564726726 to 0.0002085324984418277. Saving best weights.\n",
      "Epoch 4/50, Train Loss: 0.00032217115787336965, Validation Loss: 0.0001953703835875894\n",
      "Validation loss improved from 0.0002085324984418277 to 0.0001953703835875894. Saving best weights.\n",
      "Epoch 5/50, Train Loss: 0.00030865683073760846, Validation Loss: 0.00019177512757466244\n",
      "Validation loss improved from 0.0001953703835875894 to 0.00019177512757466244. Saving best weights.\n",
      "Epoch 6/50, Train Loss: 0.0002970209762097249, Validation Loss: 0.0001810241560429967\n",
      "Validation loss improved from 0.00019177512757466244 to 0.0001810241560429967. Saving best weights.\n",
      "Epoch 7/50, Train Loss: 0.00029088457719265423, Validation Loss: 0.0001745335244614485\n",
      "Validation loss improved from 0.0001810241560429967 to 0.0001745335244614485. Saving best weights.\n",
      "Epoch 8/50, Train Loss: 0.00028642329781838834, Validation Loss: 0.00017391240843024397\n",
      "Validation loss improved from 0.0001745335244614485 to 0.00017391240843024397. Saving best weights.\n",
      "Epoch 9/50, Train Loss: 0.00028040183642326366, Validation Loss: 0.00017877076856736372\n",
      "No improvement for 1 epochs.\n",
      "Epoch 10/50, Train Loss: 0.00027749215364925186, Validation Loss: 0.00016795033813799982\n",
      "Validation loss improved from 0.00017391240843024397 to 0.00016795033813799982. Saving best weights.\n",
      "Epoch 11/50, Train Loss: 0.00027167160426628303, Validation Loss: 0.00016852212523991146\n",
      "No improvement for 1 epochs.\n",
      "Epoch 12/50, Train Loss: 0.0002691974525679935, Validation Loss: 0.00016150723495772596\n",
      "Validation loss improved from 0.00016795033813799982 to 0.00016150723495772596. Saving best weights.\n",
      "Epoch 13/50, Train Loss: 0.00026881916548138847, Validation Loss: 0.0001648712701054721\n",
      "No improvement for 1 epochs.\n",
      "Epoch 14/50, Train Loss: 0.000265937010010557, Validation Loss: 0.00016526669565086085\n",
      "No improvement for 2 epochs.\n",
      "Epoch 15/50, Train Loss: 0.0002691243556805504, Validation Loss: 0.00017568039733468235\n",
      "No improvement for 3 epochs.\n",
      "Epoch 16/50, Train Loss: 0.000261358471512761, Validation Loss: 0.0001828913180958549\n",
      "No improvement for 4 epochs.\n",
      "Epoch 17/50, Train Loss: 0.00026566759731767956, Validation Loss: 0.00016063013205907669\n",
      "Validation loss improved from 0.00016150723495772596 to 0.00016063013205907669. Saving best weights.\n",
      "Epoch 18/50, Train Loss: 0.0002596769208656356, Validation Loss: 0.00016495690807229283\n",
      "No improvement for 1 epochs.\n",
      "Epoch 19/50, Train Loss: 0.00025882372679105094, Validation Loss: 0.00015657861583906143\n",
      "Validation loss improved from 0.00016063013205907669 to 0.00015657861583906143. Saving best weights.\n",
      "Epoch 20/50, Train Loss: 0.0002588193862374014, Validation Loss: 0.00015746414174461294\n",
      "No improvement for 1 epochs.\n",
      "Epoch 21/50, Train Loss: 0.00025569376288226423, Validation Loss: 0.00015663944832883332\n",
      "No improvement for 2 epochs.\n",
      "Epoch 22/50, Train Loss: 0.0002534655165664262, Validation Loss: 0.00015860299113703503\n",
      "No improvement for 3 epochs.\n",
      "Epoch 23/50, Train Loss: 0.0002534952898896735, Validation Loss: 0.00015993921190227465\n",
      "No improvement for 4 epochs.\n",
      "Epoch 24/50, Train Loss: 0.0002525798766413141, Validation Loss: 0.00015205790275931984\n",
      "Validation loss improved from 0.00015657861583906143 to 0.00015205790275931984. Saving best weights.\n",
      "Epoch 25/50, Train Loss: 0.00025277872311902776, Validation Loss: 0.0001591684273596151\n",
      "No improvement for 1 epochs.\n",
      "Epoch 26/50, Train Loss: 0.03311049160878375, Validation Loss: 0.00038826624037951595\n",
      "No improvement for 2 epochs.\n",
      "Epoch 27/50, Train Loss: 0.0005687842852848067, Validation Loss: 0.00031607711636426567\n",
      "No improvement for 3 epochs.\n",
      "Epoch 28/50, Train Loss: 0.0004941348609156076, Validation Loss: 0.0002992720465452077\n",
      "No improvement for 4 epochs.\n",
      "Epoch 29/50, Train Loss: 0.000460237510445387, Validation Loss: 0.00026926452521175675\n",
      "No improvement for 5 epochs.\n",
      "Early stopping due to no improvement in validation loss.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import torch.optim as optim\n",
    "\n",
    "num_epochs = 50\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "best_model_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for imgs, depths in train:\n",
    "        imgs = imgs.to(device)\n",
    "        depths = depths.to(device)\n",
    "        outputs = model(imgs)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, depths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, depths in val:\n",
    "            imgs = imgs.to(device)\n",
    "            depths = depths.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, depths)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(val)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss}, Validation Loss: {val_loss}\")\n",
    "\n",
    "    # Check for improvement\n",
    "    if val_loss < best_val_loss:\n",
    "        print(f\"Validation loss improved from {best_val_loss} to {val_loss}. Saving best weights.\")\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement for {patience_counter} epochs.\")\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping due to no improvement in validation loss.\")\n",
    "        break\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "model.load_state_dict(best_model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f0b1aef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T19:44:55.987614Z",
     "iopub.status.busy": "2024-12-23T19:44:55.987364Z",
     "iopub.status.idle": "2024-12-23T19:44:56.019355Z",
     "shell.execute_reply": "2024-12-23T19:44:56.018624Z"
    },
    "papermill": {
     "duration": 0.039634,
     "end_time": "2024-12-23T19:44:56.020847",
     "exception": false,
     "start_time": "2024-12-23T19:44:55.981213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model, \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d496423f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T19:44:56.033340Z",
     "iopub.status.busy": "2024-12-23T19:44:56.033058Z",
     "iopub.status.idle": "2024-12-23T19:44:56.613030Z",
     "shell.execute_reply": "2024-12-23T19:44:56.612092Z"
    },
    "papermill": {
     "duration": 0.588238,
     "end_time": "2024-12-23T19:44:56.614962",
     "exception": false,
     "start_time": "2024-12-23T19:44:56.026724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_dir_test = '/kaggle/input/task-4-1/test'\n",
    "image_files_test = sorted(os.listdir(image_dir_test))\n",
    "\n",
    "imgs_test = []\n",
    "\n",
    "for i in range(len(os.listdir(image_dir_test))):\n",
    "    imgs_test.append(cv2.imread(os.path.join(image_dir_test, image_files_test[i])))\n",
    "\n",
    "imgs_test = np.array(imgs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abb2f80d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T19:44:56.627208Z",
     "iopub.status.busy": "2024-12-23T19:44:56.626961Z",
     "iopub.status.idle": "2024-12-23T19:44:56.631394Z",
     "shell.execute_reply": "2024-12-23T19:44:56.630616Z"
    },
    "papermill": {
     "duration": 0.011675,
     "end_time": "2024-12-23T19:44:56.632609",
     "exception": false,
     "start_time": "2024-12-23T19:44:56.620934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 160, 256, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03792cb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T19:44:56.644140Z",
     "iopub.status.busy": "2024-12-23T19:44:56.643932Z",
     "iopub.status.idle": "2024-12-23T19:44:56.660371Z",
     "shell.execute_reply": "2024-12-23T19:44:56.659728Z"
    },
    "papermill": {
     "duration": 0.023675,
     "end_time": "2024-12-23T19:44:56.661626",
     "exception": false,
     "start_time": "2024-12-23T19:44:56.637951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = [transforms.ToTensor()(imgs_test[i]) for i in range(len(imgs_test))]\n",
    "test = DataLoader(data, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "074bbedc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T19:44:56.675887Z",
     "iopub.status.busy": "2024-12-23T19:44:56.675679Z",
     "iopub.status.idle": "2024-12-23T19:44:59.340994Z",
     "shell.execute_reply": "2024-12-23T19:44:59.340254Z"
    },
    "papermill": {
     "duration": 2.673838,
     "end_time": "2024-12-23T19:44:59.342492",
     "exception": false,
     "start_time": "2024-12-23T19:44:56.668654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for imgs in test:\n",
    "        imgs = imgs.to(device)\n",
    "        outputs = model(imgs)\n",
    "        preds.extend(outputs.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2ea7afd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T19:44:59.354680Z",
     "iopub.status.busy": "2024-12-23T19:44:59.354435Z",
     "iopub.status.idle": "2024-12-23T19:45:00.496184Z",
     "shell.execute_reply": "2024-12-23T19:45:00.495501Z"
    },
    "papermill": {
     "duration": 1.149469,
     "end_time": "2024-12-23T19:45:00.497757",
     "exception": false,
     "start_time": "2024-12-23T19:44:59.348288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = np.array(preds)\n",
    "preds.shape\n",
    "preds = (preds * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca784ed4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T19:45:00.509946Z",
     "iopub.status.busy": "2024-12-23T19:45:00.509712Z",
     "iopub.status.idle": "2024-12-23T19:45:02.739424Z",
     "shell.execute_reply": "2024-12-23T19:45:02.738717Z"
    },
    "papermill": {
     "duration": 2.237368,
     "end_time": "2024-12-23T19:45:02.740908",
     "exception": false,
     "start_time": "2024-12-23T19:45:00.503540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = \"output_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for idx, img in enumerate(preds):\n",
    "    img = img.transpose(1, 2, 0)\n",
    "    filename = os.path.join(output_dir, f\"gt_{idx:05d}.png\")\n",
    "    cv2.imwrite(filename, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6d119c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T19:45:02.753356Z",
     "iopub.status.busy": "2024-12-23T19:45:02.753059Z",
     "iopub.status.idle": "2024-12-23T19:45:04.338815Z",
     "shell.execute_reply": "2024-12-23T19:45:04.338091Z"
    },
    "papermill": {
     "duration": 1.593533,
     "end_time": "2024-12-23T19:45:04.340390",
     "exception": false,
     "start_time": "2024-12-23T19:45:02.746857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "folder_to_zip = \"output_images\"\n",
    "zip_filename = \"zipped_folder.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for root, _, files in os.walk(folder_to_zip):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            arcname = os.path.relpath(file_path, folder_to_zip)\n",
    "            zipf.write(file_path, arcname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2322b7bc",
   "metadata": {
    "papermill": {
     "duration": 0.005384,
     "end_time": "2024-12-23T19:45:04.351580",
     "exception": false,
     "start_time": "2024-12-23T19:45:04.346196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6297667,
     "sourceId": 10192589,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6305732,
     "sourceId": 10203895,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3895.430861,
   "end_time": "2024-12-23T19:45:08.873425",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-23T18:40:13.442564",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
